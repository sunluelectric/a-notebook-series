\chapter*{Preface}

Artificial intelligence (AI) was originally a research topic under the scope of control systems, and it is primarily used for system identification (``machine learning was used to be called system identification'', as some professors say). Its artificial neuron network (ANN) structure is a promising approach for building highly nonlinear and data driven self-tuning functions.

Due to the limitation of computational resources in the past years, training ANN with massive size was hardly possible. With the advancement of computer and material science in the beginning of the 21st centry, in particular the development of GPU and TPU, nowadays we can manage networks with dozens of layers, each containing hundreds of neurons. This is referred as the deep learning (DL) network structure. With DL as the building block, we have invented convolutional neural networks (CNN) and recurrent neural networks (RNN), which are effective at finding trends in spacial and time-based data, respectively. The proposition of transformers, yet another attention-based deep learning structure, has taken natural language processing to the next level.

AI has grown so significantly in the past decades that it is now considered a separate area apart from control systems, and it is drawing more and more attentions than control systems. To put it in perspective, while a classic textbook on control systems may have 10,000+ citations records after years since its publication, a famous conference paper on modern AI can easily have 50,000+ citations after a few months.

This notebook does not focus on the introduction of basic AI mechanisms, as they are already covered in control systems related notebooks. The purpose of this notebook is mainly to keep up-to-date with the latest technology in AI, starting from transformer and its applications in chatbot, the most famous of which being ChatGPT developed by OpenAI.

Some part of this notebook is written by ChatGPT-4.