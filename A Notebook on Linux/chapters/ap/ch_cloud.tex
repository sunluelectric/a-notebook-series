\chapter{Cloud Computing}

\myabb{Amazon Web Service}{AWS}, Microsoft Azure, \myabb{Google Cloud Platform}{GCP}, etc., are examples of services provided by famous cloud service providers. Many cloud services are closely tied to Linux. In this appendix chapter, a general introduction to cloud services is given. \myabb{Amazon Web Service}{AWS} services are then introduced as examples. Notice that similar services are very likely provided by other cloud service providers as well.

\section{Introduction to Cloud Services}

\mync{Cloud services} refer to a collection of managed cloud-based platforms and services including computing, networking, data storing, and many more. The most important advantage of cloud-based solutions, comparing with the traditional data-center-based solutions, is that it can be easily scaled up and down with little or no blackout time, allowing customers to pay only for operating expenses but not capital expenses and redundancies. Cloud solutions are famous for high availability, robustness, accessibility and efficiency.

\subsection{Services Modes}

When developing applications on the cloud, the user and the cloud service provider share the responsibilities to provide and sustain the applications. There are at least the following different cloud services modes. 
\begin{itemize}
	\item \myabb{Infrastructure as a Service}{IaaS}
	\item \myabb{Platform as a Service}{PaaS}
	\item \myabb{Function as a Service}{FaaS}, also known as serverless.
	\item \myabb{Software as a Service}{SaaS}
\end{itemize}
The modes differ mainly on the way responsibilities are shared. Details are given in Table \ref{tab:cloudservicetier}.

\begin{table}[!htb]
	\centering
	\caption{Different modes of cloud services and the corresponding responsibilities shared between the cloud service provider and the user.} \label{tab:cloudservicetier}
	\begin{tabularx}{\textwidth}{cccccc}
		\hline
		\multirow{2}{*}{Model} & \multirow{2}{*}{Hardware} & App & APP & APP & \multirow{2}{*}{Examples} \\ 
		& & Runtime & Coding & Features & \\ \hline
		IaaS & C & U & U & U & Virtual machine \\
		PaaS & C & C & U & U & Cloud-based website \\
		FaaS & C & C & C & U & AWS Lambda function \\
		SaaS & C & C & C & C & Microsoft 365 \\
		\hline
	\end{tabularx}
	\begin{flushleft}
		\footnotesize
		C: prepared by cloud service provider; \\
		U: prepared by user.
	\end{flushleft}
\end{table}

The most popular cloud services are \mync{public cloud services} provided by Amazon, Microsoft, Google, IBM, etc. Notice that public cloud services do not make up the entire cloud service market. Many enterprises also have \mync{private cloud services} on premises and their employees can connect to the cloud from the internal \myabb{Local Area Network}{LAN}. There are also \mync{hybrid cloud services} that integrate private and public clouds, allowing a user to use services provided by the public clouds while storing sensitive data in the private clouds.

Main public cloud providers include \myabb{Amazon Web Service}{AWS}, Microsoft Azure, \myabb{Google Cloud Platform}{GCP}, and many more. While there are overlaps among the services they provide, each of them usually has some unique features as selling points, such as proprietary database management systems, etc. The impression is that \myabb{Amazon Web Service}{AWS} focuses more on \myabb{Infrastructure as a Service}{IaaS}, hence more flexible, while Azure focuses more on \myabb{Platform as a Service}{PaaS} and \myabb{Software as a Service}{SaaS}, hence more available and easier to use. The user should choose the cloud service provider based on the problem and there is not a globally best cloud service provider for all problems.

\subsection{Services Types}

There are variety of cloud services. This section tries to categorize the most commonly seen ones into the following types.
\begin{itemize}
	\item Security
	\begin{itemize}
		\item Identity management and access control
		\item Data encryption
		\item Secret management
		\item Cloud services monitoring
	\end{itemize}
	\item Computing
	\begin{itemize}
		\item \myabb{Virtual Machine}{VM}
		\item Serverless functions
	\end{itemize}
	\item Storage
	\item Database
	\begin{itemize}
		\item \myabb{Relational Database}{RDB}
		\item Non-relational Database
		\item Big data
	\end{itemize}
	\item Network
	\begin{itemize}
		\item Virtual network
		\item \myabb{Domain Name System}{DNS} service
	\end{itemize}
	\item Others
	\begin{itemize}
		\item System back up
		\item Load balancing
		\item Messages Queue
		\item Caching
		\item Deployment automation
		\item Cloud migration
	\end{itemize}
\end{itemize}

In the remainder of this appendix chapter, \myabb{Amazon Web Service}{AWS} services are used as examples to demonstrate how the above services are implemented and how they can work together to deploy an application.

\section{AWS Basics}

AWS defines the following concepts.
\begin{itemize}
	\item \mync{AWS Region}
	
	An AWS region refers to a physical, geographic location consisting of multiple (at least 3) isolated and physically separated data centers groups (known as availability zone). Different regions may provide different cloud services at different prices. When deploying a service, it is often deployed at a select region of the users' choice. There are also global services and cross-region services.
	
	\item \mync{Availability Zone}[AZ]
	
	An AZ refers to a group of closely distributed data centers. There are at least 3 AZs in a region. It is assumed that different AZs are independent and fault-tolerant, while inside an AZ all the servers are connected via low-latency networks. When deploying a data-storage related service in a region (for example, databases), copies of the service might be automatically deployed across multiple AZs for robustness.
	
	\item \mync{Edge Locations}
	
	Edge locations are a global network of specialized data centers distinct from AWS Regions and AZs. They are AWS managed facilities meant to be built close to the user end to provide fast data caching and to make the data more available to the users.   
	
\end{itemize}

\section{AWS Identification Management}

AWS introduces \mync{Identity and Access Management}[IAM] to manage user accounts and their privileges. 

\subsection{IAM User and Role Management}

When a user registers an account with IAM, that account is known as the root account. It ultimately manages all the users and services and pay their costs. It is recommended that
\begin{itemize}
	\item Always enable \myabb{Multifactor Authentication}{MFA} for the root account (as well as other accounts) so that the account is protected.
	\item Limit the use of root account to the minimum. Create user accounts or groups for their corresponding tasks, including admin tasks, and follow the principle of least privilege.
\end{itemize}

AWS introduces the concepts of user, role and policy. They are introduced below.
\begin{itemize}
	\item User and user group
	
	A user is a virtual representation of a person or an application that needs access to the cloud services. A person user can login to the system with their \mync{access key} from the console. A user or an application can login to the system with their \mync{secret access key} from \myabb{Command Line Interface}{CLI} or \myabb{Application Interface}{API}.
	
	A user by itself does not come with any privilege or access to any AWS resource. It simply allows AWS to identify ``who is speaking''. They gain their privilege from the roles assigned to them. When a user is added to a group, they automatically inherit the roles (or privileges) of that group.
	
	User account is often permanent. 
	
	\item Role
	
	A role is a collection of privilege and access to specific AWS resources. Different from a user, a role is not about ``who is speaking'' but about ``what they can do''. A role can be assumed to a user, in which case the user gains the privilege and access to the AWS resources specified by the role.
	
	The roles assigned to a user can be permanent or temporary. \myabb{AWS Security Token Service}{AWS STS} can be used to manage temporarily assigned roles.
	
	\item Policy
	
	A policy is a piece of JSON object (or similar) that represents the contents of roles as well as the rules about which users can assume them.
	
	AWS provides readily-available policies for commonly seen roles. The user can also write their own roles. An example of a policy is given below.
	\begin{lstlisting}
{
	"Version": "2012-10-17",
	"Statement": [
	{
		"Effect": "Allow",
		"Action": "*",
		"Resources": "*"
	}
	]
}
	\end{lstlisting}
	
\end{itemize}

\subsection{IAM Database Authentication}

In addition to user management and their corresponding roles management, IAM also provides database authentication service. It can generate temporary access tokens, using which a user or a program can access the AWS-managed database without using a password.

Notice that IAM database authentication has some limits. For example, it does not support all types of databases. Cloud activities done via IAM database authentication is sometimes not logged by monitoring services. It cannot be efficiently scaled up when there are many connections.

\section{AWS Storage}

There at least the following storage types in AWS.
\begin{itemize}
	\item Object storage: the storage of non-executable files, similar with OneDrive, Google Drive, iCloud Storage, etc.
	\item Block storage: the storage attached to VMs, similar with ``C Drive'' on a personal computer.
	\item Shared storage: the storage that can be mounted to multiple VMs, similar with \myabb{Network Attached Storage}{NAS} in an office.
\end{itemize}
Notice that many AWS managed services also come with storage, for example, AWS managed database. Those storage is not covered, as they are managed by AWS and are never exposed to the user.

\subsection{AWS Simple Storage Service}

\mync{AWS Simple Storage Service}[AWS S3] is the default and most commonly used object storage of AWS. It has the following features.

\begin{itemize}
	\item Object storage, hence non-executable.
	\item Unlimited total storage size.
	\item Up to $5$TB size limit for a single file.
	\item Each file is assigned with a URL that looks like the following
	\begin{lstlisting}
https://<bucket name>.s3.<region>.amazonaws.com/<file name>
	\end{lstlisting}
	where \verb|bucket name| is the name of S3 bucket of the file, and \verb|file name| the name of the file that may contain sub-directories known as prefix. Notice that bucket name must be globally unique.
	\item Different storage tiers are available, each with different technical properties and business model. More to be introduced later.
	\item Server-side encryption can be enabled if the user chooses to do so.
\end{itemize}

\subsection{AWS S3 Object}

An AWS S3 object contains at least the following information.
\begin{itemize}
	\item Key: the name of the object or file, including prefix.
	\item Value: the content of the object.
	\item Version ID: when versioning is enabled, multiple versions of the same file can be saved, each with a version ID.
	\item Other metadata: last modified data, etc., of the file.
\end{itemize}

It is worth mentioning that versioning is disabled by default, and the user can activate versioning for each and every of their specified object. Once enabled, version ID is activated and it cannot be terminated, but only be suspended.

Versioning can be used for files back up. Some features of S3, such as cross-region back up, require versioning to be enabled as a prerequisite.

As briefly mentioned earlier, S3 provides different storage tiers. Versioning can be integrated with life cycle rules, with which older versions of a file can me automatically moved into a low-cost storage tier. More about storage tiers are introduced later.

\subsection{AWS S3 Storage Tiers}

As of this writing, AWS S3 offers at least the following storage tiers as summarized in Table \ref{tab:s3tiers}.

\begin{table}[!htb]
	\centering
	\caption{Different AWS S3 storage tiers and their costs as of this writing.} \label{tab:s3tiers}
	\begin{tabularx}{\textwidth}{lcc}
		\hline
		Tier & Storage$^*$ (/GB) & IO$^{**}$ (/$1$K request)  \\ \hline
		S3 Standard & 0.0230 & 0.0004 \\
		S3 Standard Infrequent Access & 0.0125 & 0.0010  \\
		S3 One Zone Infrequent Access & 0.0100 & 0.0010 \\
		S3 Glacier Instant Retrieval & 0.0040 & 0.0100 \\
		S3 Glacier Deep Archive & 0.0001 & 0.0004 \\
		S3 Intelligent Tiering & \multicolumn{2}{c}{Dynamic} \\
		\hline
	\end{tabularx}
	\begin{flushleft}
		\footnotesize
		$^*$ Notice that the in each storage tier, the average cost per TB may also be affected by the total storage size. The larger the total size, the cheaper per TB may cost. \\
		$^{**}$ Write and read cost may differ. The table lists only read cost, i.e., the cost per SELECT request.
	\end{flushleft}
\end{table}

From Table \ref{tab:s3tiers}, it is clear that different storage tiers can be used for different purposes. For example, while S3 Standard is often used for general purpose storage, S3 Glacier can be used for data back up. Additional limits may apply. For example, S3 Glacier often requires a minimum storage duration of $90$ (Instant Retrieval) or $180$ (Deep Archive) days. Objects deleted prior to the minimum storage duration incur a pro-rated charge.

\subsection{AWS S3 Storage Protection}

Following protections can be enabled for AWS S3.
\begin{itemize}
	\item Data lock can be used to prevent data from being accidentally deleted or modified.
	\item Data encryption can be used to prevent data leakage.
	\item Data access control can be used to manage the services and networks that can access the stored items.
	\item Monitoring services can be used to monitor suspicious behaviors and notify the users of such behavior if any.
\end{itemize}

Data lock. AWS S3 uses S3 Object Lock that stores objects using write-once-read-many model. When it is effective, the data, once written, cannot be modified or removed. S3 Object Lock can be applied on single object or on the entire bucket. S3 Object Lock can work in governance mode where only specified persons can change the object, or in compliance mode where nobody can change the object within the time frame.

Encryption. It is possible to enforce the use of HTTPS and SSL/TLS when transmitting data. Server-side encryption can be enabled or enforced, and there are several modes for that, including SSE-S3 (S3 built-in encryption), SSE-KMS (AWS key management based encryption) and SSE-C (customer key management based encryption).

Access control. S3 Access Point can be used to manage virtual networks that can access S3 bucket. \myabb{Multifactor authentication}{MFA} can be used on S3 when performing deletion.

Monitoring. AWS has system-wise services to monitor the system behavior and notification services to notify the user on different situations.

\subsection{AWS S3 Performance Optimization}

In this context, ``performance'' refers to the maximum IO in a given period of time. There are multiple ways to improve S3's performance.
\begin{itemize}
	\item Write. Use multipart uploads for fast file uploading. Multipart upload is compulsory for files with size larger than $5$GB.
	\item Read.
	\begin{itemize}
		\item Use S3 Byte-Range Fetches for faster downloading.
		\item Use S3 Replica and S3 Transfer Acceleration to create bucket backup within or cross region, which helps with reading performance.
		\item Use prefix to improve performance when there are many files inside a bucket.
	\end{itemize}
\end{itemize}

Notice that SSE-KMS based S3 encryption limits the performance. Consider using other encryption methods for frequent IO.

\subsection{AWS Elastic Block Store}

\mync{AWS Elastic Block Store}[AWS EBS] is the default block storage of AWS. It is often attached to a \myabb{virtual machine}{VM}. There are two types of EBS volumes, namely the \myabb{Solid-State Drive}{SSD} and the \myabb{hard Disk Drive}{HDD}. SSD is faster than HDD and it is recommended for general purposes. HDD can be used only if the VM requires large data storage space with less cost. For a VM, the OS and boot script must be saved in SSD.

Commonly seen EBS are listed below.
\begin{itemize}
	\item General purpose SSD volumes
	\begin{itemize}
		\item \verb|gp3| high performance
		\item \verb|gp2|
	\end{itemize}
	\item Provisioned IOPS SSD volumes
	\begin{itemize}
		\item \verb|io2| block express
		\item \verb|io1|
	\end{itemize}
	\item Throughput optimized HDD volumes
	\begin{itemize}
		\item \verb|st2| throughput optimized HDD
		\item \verb|st1| cold HDD
	\end{itemize}
\end{itemize}

EBS volumes can be scaled or changed types on the fly.

\subsection{AWS EBS Snapshot}

EBS Snapshots are point-in-time photographs of EBS volumes. EBS Snapshot is useful as a VM instance back up. It can be used to quickly launch and configure a new VM instance, and it can be shared among different AWS accounts. By default, EBS Snapshot data is encrypted.

\myabb{Amazon Machine Image}{AMI} is the AWS maintained re-usable image provided by AWS that contains information required to launch an VM instance. EBS Snapshot is one of the two commonly seen AMI types, and the other is Instance Store.

Unlike EBS Snapshot which is incremental by nature, Instance Store is simply a launching template that can be stored in AWS S3. Hence, EBS Snapshot and Instance Store differs in many ways. For example, consider a new instance started from EBS volume. When it is stopped, the user can save newly generated data back into the EBS Snapshot. In this way, the EBS Snapshot becomes incremental, and the user can continue its VM tasks in a later time. The same does not apply to VM instances launched from Instance Store. In other words, Instance Store is stationary and not incremental by nature.

It is safe to reboot VM instances launched from both EBS Snapshot and Instance Store without loosing data. This is because VM launched from Instance Store, just like any other VM instance, is also assigned with a temporary block storage. When the VM is terminated, the block storage is gone. It is just that the data cannot be written back into the Instance Store.

\subsection{AWS Elastic File System}

\myabb{AWS Elastic File System}{AWS EFS} refers to the shared storage that can be mounted by multiple VMs. The VMs can use EFS to share information. EFS provides read-after-write consistency. There are the following different types of EFS.
\begin{itemize}
	\item EFS (general purpose): distributed and highly resilient storage for Linux-based VM instances
	\item Amazon FSx for Windows: centralized storage for Windows-based VM instances or Windows-based applications
	\item Amazon FSx for Lustre: high-speed high-performance distributed storage for \myabb{High Performance Computing}{HPC}
\end{itemize}

\section{AWS Computing}

There are at least two AWS managed services that can be used to perform computing and process data.
\begin{itemize}
	\item AWS managed \myabb{Virtual Machine}{VM}
	\item AWS Lambda
\end{itemize}
Both are introduced in this section.

\subsection{AWS Elastic Cloud Computing}

\myabb{AWS Elastic Cloud Computing}{AWS EC2} is AWS's cloud-based \myabb{Virtual Machine}{VM} service. It allows the user to deploy a cloud-based VM of their specified computation core, memory, OS, network adapter, etc. The user can easily scale up or down the resources with no or very little black out time, and pay only the running cost on-demand. 

The user can launch and login to the EC2 instance and configure it and install software, very much like login to a personal computer. The VM can also be automatically launched and configured with automation scripts. For example, the user can specify bootstrap script (also known as user data) when launching an VM instance. The bootstrap script is automatically executed after the booting of the VM. It is often used to configure the initial status of the system and to install software.

With properly assigned roles, the EC2 can access the Internet as well as other AWS managed resources such as databases to perform tasks or to host an application.

\subsection{EC2 Charging Model}

The cost of EC2 mainly depends on the resources used by the VM instance. The more powerful the \myabb{Central Processing Unit}{CPU} and \myabb{Graphics Processing Unit}{GPU}, the larger and more powerful EBS and network adapter, the longer the runtime, the higher the cost. Notice that the runtime cost may be float depending on the demand. The charge starts when a VM is launched, and stops immediately when it is terminated. 

Notice that EBS and network adapter may not be automatically removed with the VM. Do remember to remove them as well after the VM is terminated to avoid redundant cost.

The user is able to choose OS and pre-installed software. Some of the software may come with a license fee, which will also be charged as part of the VM cost.

In addition to the default on-demand charging, there are other charging models as follows.
\begin{itemize}
	\item Spot. Purchase unused capacity at a cheaper price. Specify the budget threshold, and EC2 executes only when the float charging rate is below the threshold. The EC2 instance temporarily stops when the charging rate goes above the threshold.
	\item Reserved. Reserve the VM capacity of 12 or 36 months with fixed price. Use the VM anytime within the time frame with no additional charge. The user can pay up front, and pay the remaining monthly. The longer the reservation and the more upfront, the higher discount (up tp $72\%$) is given.
	\item Dedicated. AWS dedicates a server for the user to run its VM. This is expensive but can be useful when the VM has to be deployed in such a way due to licensing requirement or security concerns. 
\end{itemize}

\subsection{EC2 Security Group}

EC2 Security Group plays as the firewall of the VM. It is basically a table that describes what inbound and outbound connectivity are allowed in the given network, the IP addresses, the port, and the protocol.

An example is given below in Fig. \ref{fig:aws_ec2_security_group}. By default, the Security Bound allows outbound traffic, and it is put into the default \myabb{Virtual Private Cloud}{VPC} (more to be introduced in later sections) that has Internet access. That explains why a EC2 instance can access the Internet by default.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\textwidth]{chapters/ap/figures/aws_ec2_security_group.png}
	\caption{Creating Security Group for EC2.} \label{fig:aws_ec2_security_group}
\end{figure}

Once a Security Group is defined, it can be re-used for multiple EC2 instances. It is possible to modify or change Security Group for a EC2 instance on the fly.

Notice that the use of Security Group is not limited to EC2. Security Group for other services, such as private networks, will be introduced in later sections. When there is a gateway, there can be a security group.

\subsection{EC2 Network Adapter}

A EC2 instance connects to the Internet or to other devices in the network via a network adapter, also known as a network interface. When launching a EC2 instance, a network adapter is attached by default and outbound Internet access is enabled. There are at least the following network adapters that the user can choose when launching a EC2 instance.
\begin{itemize}
  \item \myabb{Elastic Network Interface}{ENI}: the default general purpose low-cost network adapter
  \item Enhanced Networking: the faster network adapter with a bandwidth of $10$Gbps to $100$Gbps
  \item \myabb{Elastic Fabric Adapter}{EFA}: the very-high-performance network adapter that requires large and in-time data transmission
\end{itemize}

It is possible to attach multiple network adapters to a EC2 instance. However, there must be at least one network interface, known as the primary network interface, attached to the instance. Network interface can be attached to a EC2 instance when it is running, stopped, or being launched. They are known as hot attach, warm attach and cold attach, respectively.

\subsection{EC2 Connectivity and Access Control}

When an EC2 is launched, the user can login to the EC2 instance via several ways. One of the easiest and most commonly used way is introduced below.
\begin{enumerate}
  \item When launching an EC2 instance, the user should create (or use an existing) key pair and attach it to the EC2 instance. This involves downloading the private key to the user's local machine. Later, the user can remote login to the EC2 instance with the private key. Consider changing the permission of the private key using \texttt{chmod 400 <key name>.pem}.  When launching the EC2 instance, select allow SSH login. This will enable SSH login in the Security Group of the EC2 instance.
  \item Once the EC2 instance is launched, get its public IP address from AWS console.
  \item SSH login to the EC2 instance using the IP address and the private key as follows:
  \begin{lstlisting}
ssh ec2-user@<ip address> -i <key name>.pem
  \end{lstlisting}
  where \verb|ec2-user| is the default login user name.
  \item Use the EC2 normally just like any other VM.
\end{enumerate}

When an EC2 is launched, by default it is a independent \myabb{Virtual Machine}{VM} and has no access to other AWS services such as databases. For VMs that need to access AWS services, it is recommended that a role be created and attached to the EC2 instance. When a user logs into the system, they can temporarily assign their role to the EC2 instance as follows.

\begin{enumerate}
    \item Remote login to the system as introduced earlier. Note that at this point it is simply an individual VM and has no access to any AWS service. The EC2 instance does not identify the user. The private key \verb|.pem| file cannot be used to identify the user who login to the system.
    \item Run command \verb|aws configure| and follow the configuration wizard. At some point, it asks the user for the secret access key pair. Once the user is identified, the user's role is temporarily attached to the EC2 instance.
\end{enumerate} 


\subsection{EC2 Placement Group and Scaling Group}

Sometimes it is desirable to deploy multiple EC2 instances for the following reasons.
\begin{itemize}
  \item Multiple EC2 instances, each with a different task, need to work together for the application.
  \item Multiple EC2 instances are deployed to enhance system robustness, in which case an instance is a back up to another instance.
  \item Multiple EC2 instances, each with identical configuration and perform the same task, is deployed as a scale up to the single instance to share load.
\end{itemize}

EC2 Placement Group addresses the first and second points, while Auto-Scaling Group addresses the third. They are introduced below. There are at least the following different types of EC2 Placement Groups.
\begin{itemize}
  \item Cluster Placement
  
  Cluster Placement places multiple EC2 instances with different tasks on the same rack for low latency and high throughput.
  
  \item Spread Placement
  
  Spread Placement places multiple EC2 instances across multiple hardware racks, each rack with its own power and network source. There is at most one instance on a rack. In some cases, it is possible to spread the instances across racks in different AZs in the same region. This is helpful with enhancing the system robustness.
  
  However, there is a limited number of racks in an AZ or in a region, and hence it is challenging to deploy massive instances (in the scale of hundreds or even thousands) using Spread Placement.
  
  \item Partition Placement
  
  Partition Placement is the hybrid of the two placements. It defines ``logical partitions'', where each partition represents a rack. EC2 instances in the same partition enjoys low latency, while EC2 instances in different partitions are physically separated and hence unlikely to fail altogether.
  
  In the case where many instances need to be deployed and it is challenging to use Spread Placement, consider Partition Placement instead, and let some instances share the same partition.
  
\end{itemize}

EC2 Auto-Scaling Group, on the other hand, allows the user to automatically scale up and down the number of the identically deployed EC2 instances depending on the computation burden. From this sense, EC2 Auto-Scaling Group is like a EC2 orchestration tool.

\subsection{AWS Lambda Function}

AWS Lambda is an event-driven FaaS computing service. The user provides the script and specify the trigger. Upon triggered, AWS executes the script which allows it to process data and manipulate AWS managed services accordingly. Since AWS Lambda needs to access AWS managed services, it should be assigned with a proper role. The user does not need to worry about the allocation of the resources such as VMs or memories to execute the script. The computation runtime and memory of a single invocation is limited to $15$ minutes and $10$GB, respectively. 

Many AWS managed services and activities can be used as the trigger for AWS Lambda. The full list is given in the official website, and some commonly seen ones are given below.
\begin{itemize}
	\item AWS EventBridge
	\item AWS DynamoDB
	\item AWS S3
	\item AWS Config
	\item AWS IoT
	\item Amazon API Gateway
	\item AWS CloudWatch Logs
	\item AWS Simple Queue Service
	\item AWS Simple Queue Service
	\item AWS Simple Email Service
\end{itemize}
Some of the services will be introduced in the remainder of this appendix chapter.

Notice that AWS EventBridge is an AWS managed event bus that is helpful with building event-driven applications. All API calls can connect to AWS EventBridge, thus triggering AWS Lambda.

\subsection{AWS Container Management}

AWS provide container orchestration tools that can be used to automatically scale up and down containers. The user needs to pay for the CPU, memory and other resources consumed by the containers, but not for the orchestration tools themselves.

\myabb{AWS Elastic Container Service}{AWS ECS} is an orchestration tool fully managed by AWS to manage containerized applications. 

\myabb{AWS Elastic Kubernetes Service}{AWS EKS} is an open-source software for container management. Notice that the user can of course deploy Kubernetes on an VM to manage their containers. It is recommended to use AWS EKS instead for such scenarios. 

AWS Fargate is a serverless, pay-as-you-go compute engine that lets the user focus on building applications without managing servers. When the user deploys a piece of code with AWS Fargate, AWS runs the code in either ECS or EKS, and charges the user at the same rate as ECS and EKS. It is especially useful then there is a unpredictable workload on a containerized application, as Fargate can automatically scale in and out based on the workload.

\section{AWS Database}

AWS supports many databases, both first-party and third-party. Third-party databases such as Microsoft SQL Server, MySQL, MariaDB, PostgreSQL, Oracle, etc., are not introduced here. This section focuses on first-party propriety databases.

AWS managed first-party databases include Amazon Aurora, DynamoDB, DocumentDB (compatible with MongoDB), MemoryDB (compatible with Redis), and many more. In this section, Aurora and DynamoDB are introduced, as they are basic and widely used.

\subsection{AWS Aurora}

AWS Aurora is an AWS managed \myabb{relational database}{RDB}. Comparing with any other RDBs, Aurora provides the following features.
\begin{itemize}
	\item Data backup. When Aurora is deployed, duplicated data is deployed. At least 3 AZs have identical copies of the data, each AZ at least 2 copies. This means that there are at least 6 copies of the data deployed, making the database very available and reliable.
	
	\item Read replica. Read replicas can be deployed, which boost the read capability.
	
	\item Database recover with read replicas. Automated failover is available with Aurora replica. It is possible to promote a read replica into a database once the primary database fails. Amazon Aurora Global Database creates cross-region read replicas, and if the primary region fails, the replicas in other regions will automatically cut over to the new primary region.
	
	\item Data snapshot sharing. Aurora snapshots are shareable with other AWS accounts.
	
\end{itemize}

Notice that both multi-AZ data backups introduced in the first bullet point and read replicas in the rest bullet points can be used to recover the system when the primary database fails. They have some differences.
\begin{itemize}
	\item Multi-AZ data backups always exist, while read replica is optional and it needs additional setup.
	\item While multi-AZ data backups are purely used for database recovering, read replicas can be used to boost read performance along with the primary database.
	\item When comes to database recovering, multi-AZ data backups usually work better. Although a read replica can be promoted to become the main database, it is updated asynchronously, and they may not have the latest data. Multi-AZ data backup based recovery is a preferred way to handle failover, and it is updated synchronously. Multi-AZ data backups based recovery also responses faster.
	\item Multi-AZ data backups always reside within a single region. For cross-region recovery, consider using cross-region read replica instead.
	
\end{itemize}

Amazon RDB Proxy is a fully management service that makes connecting Amazon RDBs, Aurora included, more scalable and secure. Amazon RDB Proxy helps with managing a large number of connections from serverless architectures (such as Lambda) to an RDB database by establishing a warm connection pool to the database. This allows applications to reuse existing connections, rather than creating new connections, for every function invocation, thus improve performance.

\subsection{AWS DynamoDB}

AWS Dynamo is a very powerful AWS managed NoSQL database that supports both key-value storage and document storage. It has the following features.
\begin{itemize}
	\item Database backup. The data is spread across 3 geographically distinct data centers. In addition, DynamoDB provides the following backup features.
	
	DynamoDB On-Demand Backup enables full backup at anytime without affecting the performance of the database. The backup is stored in the same region as the source. 
	
	DynamoDB Point-in-Time Recovery restores the database to anytime back in time, from 5 minutes to 35 days. This feature is not enabled by default. 
	
	DynamoDB Streams captures changes in the database in a time stream. When DynamoDB Streams is enabled, it captures a time-ordered sequence of item-level modifications in a DynamoDB table and durably stores the information for up to 24 hours. This feature is not enabled by default.
	
	Multi-master multi-region replication ("global table") is supported using DynamoDB streams with latency under 1 second.
	
	\item High performance. The data is saved on SDD, and it is able to handle millions of reads and writes requests per second, higher than the relational databases.
	
	\item Consistency. Eventually consistent reads is enabled by default. Strongly consistent reads can be enabled. DynamoDB Transactions automatically rolls back if a writing operation fails, i.e. guaranteeing "all-or-nothing transaction".
	
\end{itemize}

\subsection{Database Security and Connectivity}

AWS services with appropriate roles can access AWS managed databases. Some commonly seen architecture is briefly introduced.

It is possible to use IAM Database Authentication to secure a database. It works for MariaDB, MySQL and PostgreSQL. In such cases, an EC2 can access the database using profile credentials instead of a password.

AWS Lambda can be triggered by database activities, and it can also manipulate and update databases. RDB Event is an alternative to Lambda function to perform database operations. However, RDB Event is less flexible than Lambda function, later of which can be triggered by many kinds of events from a variety of AWS services. 

\section{AWS Networking}

\myabb{AWS Virtual Private Cloud}{AWS VPC} is the AWS managed networking services to build virtual \myabb{Local Area Network}{LAN} and gateways. Other services relevant to networking, such as \myabb{Domain Name Service}{DNS} tool Route 53, etc., are also introduced.

VPC is a very important component in AWS architecture, a big part of which is grouping services, putting them into different subnets, and building connectivity within and across these subnets. With that been said, networking with AWS VPC is a complex topic with tons of newly introduced concepts such as subnet, gateway, route table, endpoint, different types of IP addresses, etc. This section only gives the basics of AWS VPC.

\subsection{AWS Virtual Private Cloud}

A VPC closely resembles a private network in a traditional data center. A user can define a VPC and deploy AWS managed services inside that network, and can also configure connectivity within VPC, across VPC and from VPC to the Internet.

Some basic concepts are reviewed below. These concepts or ideas are not defined or exclusively used by AWS.
\begin{itemize}
	\item \mync{Classless Inter-Domain Routing}[CIDR]: a representation of IP address allocation. 
	
	CIDR is given in the form of \verb|x.x.x.x/y|, where \verb|x| is a value between $0$ and $255$, i.e., an $8$-digit binary value. This makes \verb|x.x.x.x| a $32$-digit IP address. The value of $y$ indicates the fixed number of digits. 
	
	For example, consider \texttt{192.168.1.0/24}. Among the $32$ digits, the first $24$ digits are fixed, and the last $8$ digits are flexible. This makes the IP address allocation \texttt{192.168.1.0} to \texttt{192.168.1.255}, with $256$ total IPs. The value of $y$ decides the number of IPs. For example, $26$ represents $64$ addresses, $24$, $256$ addresses, $16$, $65536$ addresses, and $32$ a single address.
	
	CIDR is used almost everywhere in AWS to represent IP addresses and a range of IP addresses, including security groups, route tables, etc.
	
	\item \mync{Private IP}: the IP addresses that is used inside a private network (and not used globally by the Internet). When a VPC is defined and devices and subnets are deployed inside the VPC, they are assigned with a private IP address. 
	
	Following the universally adopted convention, the following IP addresses are reserved for private IP.
	\begin{itemize}
		\item Large network: \texttt{10.0.0.0/8}
		\item Medium network: \texttt{172.16.0.0/12}
		\item Small network: \texttt{192.168.0.0/16}, widely used by home routers
	\end{itemize}
	When a router sees the above IPs, it will take them as private IP addresses. Most IP address other than the above will be taken as public IP address. (There are exceptions, for example, \texttt{127.0.0.1} for loopback, etc.)
	
	\item \mync{Network Address Translation}[NAT]: a technology used by routers to map multiple private IP addresses to a single or limited number of public IP addresses.
	
	The total number of IPv4 addresses is slightly over $4$ billion, which is not enough for each and every smart device to have a distinguished public address. Yet, for a device to be able to access the Internet, it must possesses a public IP address registered on the Internet. For that reason, a public address must be shared among multiple devices in a private network. This is done by a router. In practice, a router is assigned with a single public IP address. It manages multiple devices in a private network, each assigned with a private IP address. The router must translate the network addresses across the Internet and the private network. 
	
	When a device in the private network wants to access the Internet, the request is sent to the router, where its private IP address is translated to the public IP address that the router holds. The translation is bidirectional. When the router receives a message, it needs to identify which device the message is intended for in the private network, and translate the public IP address to the private IP address..
	
	Note that NAT will be unnecessary in the future with the spread of IPv6, which will be able to assign globally unique IP address for each and every smart device. IPv6 can produce over $3.4\times 10^{38}$ unique addresses.  
	
\end{itemize}

AWS VPC defines a stationary list of CIDR blocks of private IP addresses. Each CIDR defines a subnet. In AWS VPC, there is a size limit to each CIDR that ranges from \texttt{/28} ($16$ addresses) to \texttt{/16} ($65536$ addresses). That means, the size of a subnet in an AWS VPC ranges from $16$ to $65536$. In each subnet, the first $4$ IP addresses in a subnet by AWS and cannot be assigned by the user.

In the remainder of this section, the tools that AWS VPC uses to manage IP address assignments, connectivity and access controls. Key components include
\begin{itemize}
  \item Gateway: the router
  \item Network \myabb{Access Control List}{ACL}: firewall
  \item Route table: connectivity configuration
\end{itemize}

\subsection{AWS VPC Gateway}

A \mync{NAT gateway} is the ``router'' of a subnet. There are two types of NAT gateways, public NAT gateway and private NAT gateway. A public NAT gateway is necessary if the devices in the subnet wants Internet access. The public NAT gateway translates the private IP addresses in a subnet to a public IP address (known as \mync{elastic IP address} in AWS) assigned to that NAT gateway. Notice that the public NAT gateway is necessary only for those devices that do not possess public IP addresses. The user is able to deploy a device and assign it with a public IP address. Such a device does not require a public NAT gateway to access Internet.

Public NAT gateways and devices with public addresses connect to the \mync{Internet Gateway}[IGW] of the VPC to access the Internet. The connection from these NAT gateways and devices to the IGW is managed by the route table(s) of the VPC.

The relationship of private subnets, public NAT gateway, devices with public addresses and IGW is demonstrated in Fig. \ref{fig:aws_vpc_gateway}. 

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\textwidth]{chapters/ap/figures/aws_vpc_gateway.png}
	\caption{Devices in VPC public and private subnets accessing the Internet.} \label{fig:aws_vpc_gateway}
\end{figure}

Notice that \mync{public subnet} in this context refers to the collection of devices in the VPC that is assigned with a public IP address. By this definition, a public NAT gateway is considered a device in the public subnet.

The connectivity from the device in the private network to the NAT gateway in the public network and from the NAT gateway and the device with public IP address to the IGW are managed by route table(s) of the VPC, which will be introduced in the later Section \ref{ap:aws_vpc_route_table}.

While a public NAT gateway helps to connect devices in private subnets with the Internet, a private NAT gateway connects the devices not to the Internet but to other VPCs or on-premises network of the user.

\subsection{AWS VPC Access Control List}

\subsection{AWS VPC Route Table} \label{ap:aws_vpc_route_table}

AWS VPC uses \mync{route table}(s) to direct the network traffic. It is essentially a rule book set for the devices in a subnet that says ``if a machine in the subnet what to access IP address \texttt{x.x.x.x/y}, then direct the traffic to (device)'' and ``(device)'' can be network gateway, etc.

\subsection{AWS VPC Endpoint}

\subsection{AWS VPC Connectivity}

\subsection{AWS VPC Direct Access}








\section{Other AWS Services}

AWS Step Function is an AWS managed state machine that can be used to build data pipelines.






